{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Summariser AI"
      ],
      "metadata": {
        "id": "YatZF-hPwbF_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#install generative ai package"
      ],
      "metadata": {
        "id": "W0487fXvhYlQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages in Google Colab\n",
        "\n",
        "!pip install google-generativeai\n",
        "!pip install transformers\n",
        "!pip install torch\n",
        "!pip install nltk\n",
        "\n",
        "print(\"‚úÖ All packages installed successfully!\")\n",
        "print(\"Now you can run the main summarizer code.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eue-k--Zh2b2",
        "outputId": "133630b8-aa67-4cd6-fc06-45580f877668"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.5)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.25.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.176.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (5.29.5)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.11.7)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.14.1)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.4.1)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.73.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.7.14)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.7.14)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m90.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
            "‚úÖ All packages installed successfully!\n",
            "Now you can run the main summarizer code.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "1ARw2hg2hYko"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#multi model text summariser"
      ],
      "metadata": {
        "id": "nSz926kweaWh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "import openai\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk import FreqDist\n",
        "import heapq\n",
        "import re\n",
        "import time\n",
        "from typing import Dict, List, Optional\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Download required NLTK data\n",
        "try:\n",
        "    nltk.download('punkt', quiet=True)\n",
        "    nltk.download('punkt_tab', quiet=True)\n",
        "    nltk.download('stopwords', quiet=True)\n",
        "    print(\"‚úÖ NLTK data downloaded successfully\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è NLTK download warning: {e}\")\n",
        "    # Try alternative downloads\n",
        "    try:\n",
        "        nltk.download('all', quiet=True)\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "class TextSummarizer:\n",
        "    def __init__(self):\n",
        "        # Configure Gemini API\n",
        "        self.gemini_api_key = \"AIzaSyD0GHCUB82y5RZKYGAp0rp9p2d3CIem6UQ\"  # Your API key goes here\n",
        "        genai.configure(api_key=self.gemini_api_key)\n",
        "        # Try different model names based on availability\n",
        "        try:\n",
        "            # Try newer model names first\n",
        "            self.gemini_model = genai.GenerativeModel('gemini-1.5-flash')\n",
        "        except:\n",
        "            try:\n",
        "                self.gemini_model = genai.GenerativeModel('gemini-1.0-pro')\n",
        "            except:\n",
        "                try:\n",
        "                    self.gemini_model = genai.GenerativeModel('models/gemini-1.5-flash')\n",
        "                except:\n",
        "                    self.gemini_model = None\n",
        "                    print(\"‚ö†Ô∏è Could not load Gemini model. Will skip Gemini summarization.\")\n",
        "\n",
        "        # Initialize other models\n",
        "        self.huggingface_summarizer = None\n",
        "        self.load_huggingface_model()\n",
        "\n",
        "    def load_huggingface_model(self):\n",
        "        \"\"\"Load HuggingFace summarization model\"\"\"\n",
        "        try:\n",
        "            self.huggingface_summarizer = pipeline(\n",
        "                \"summarization\",\n",
        "                model=\"facebook/bart-large-cnn\",\n",
        "                tokenizer=\"facebook/bart-large-cnn\"\n",
        "            )\n",
        "            print(\"‚úÖ HuggingFace BART model loaded successfully\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Failed to load HuggingFace model: {e}\")\n",
        "\n",
        "    def gemini_summarize(self, text: str, summary_type: str = \"concise\") -> str:\n",
        "        \"\"\"Summarize text using Google Gemini\"\"\"\n",
        "        if not self.gemini_model:\n",
        "            return \"‚ö†Ô∏è Gemini model not available\"\n",
        "\n",
        "        try:\n",
        "            prompts = {\n",
        "                \"concise\": f\"Provide a concise summary of the following text in 2-3 sentences:\\n\\n{text}\",\n",
        "                \"detailed\": f\"Provide a detailed summary of the following text, covering all main points:\\n\\n{text}\",\n",
        "                \"bullet_points\": f\"Summarize the following text as bullet points highlighting key information:\\n\\n{text}\",\n",
        "                \"executive\": f\"Provide an executive summary of the following text suitable for business purposes:\\n\\n{text}\"\n",
        "            }\n",
        "\n",
        "            prompt = prompts.get(summary_type, prompts[\"concise\"])\n",
        "            response = self.gemini_model.generate_content(prompt)\n",
        "            return response.text.strip()\n",
        "        except Exception as e:\n",
        "            if \"403\" in str(e) or \"disabled\" in str(e).lower():\n",
        "                return f\"‚ö†Ô∏è Gemini API not enabled. Please enable it at: https://console.developers.google.com/apis/api/generativelanguage.googleapis.com/overview\"\n",
        "            elif \"404\" in str(e) or \"not found\" in str(e).lower():\n",
        "                return f\"‚ö†Ô∏è Model not found. Try updating google-generativeai: pip install --upgrade google-generativeai\"\n",
        "            return f\"Error with Gemini summarization: {e}\"\n",
        "\n",
        "    def huggingface_summarize(self, text: str, max_length: int = 150, min_length: int = 50) -> str:\n",
        "        \"\"\"Summarize text using HuggingFace BART model\"\"\"\n",
        "        try:\n",
        "            if not self.huggingface_summarizer:\n",
        "                return \"HuggingFace model not available\"\n",
        "\n",
        "            # BART has token limits, so we might need to chunk long texts\n",
        "            max_input_length = 1024\n",
        "            if len(text.split()) > max_input_length:\n",
        "                # Split into chunks and summarize each\n",
        "                chunks = self._chunk_text(text, max_input_length)\n",
        "                summaries = []\n",
        "                for chunk in chunks:\n",
        "                    result = self.huggingface_summarizer(\n",
        "                        chunk,\n",
        "                        max_length=max_length//len(chunks),\n",
        "                        min_length=min_length//len(chunks),\n",
        "                        do_sample=False\n",
        "                    )\n",
        "                    summaries.append(result[0]['summary_text'])\n",
        "                return \" \".join(summaries)\n",
        "            else:\n",
        "                result = self.huggingface_summarizer(\n",
        "                    text,\n",
        "                    max_length=max_length,\n",
        "                    min_length=min_length,\n",
        "                    do_sample=False\n",
        "                )\n",
        "                return result[0]['summary_text']\n",
        "        except Exception as e:\n",
        "            return f\"Error with HuggingFace summarization: {e}\"\n",
        "\n",
        "    def extractive_summarize(self, text: str, num_sentences: int = 3) -> str:\n",
        "        \"\"\"Create extractive summary using frequency-based approach\"\"\"\n",
        "        try:\n",
        "            # Tokenize into sentences\n",
        "            sentences = sent_tokenize(text)\n",
        "            if len(sentences) <= num_sentences:\n",
        "                return text\n",
        "\n",
        "            # Remove stopwords and calculate word frequencies\n",
        "            stop_words = set(stopwords.words('english'))\n",
        "            words = word_tokenize(text.lower())\n",
        "            words = [word for word in words if word.isalnum() and word not in stop_words]\n",
        "\n",
        "            freq_dist = FreqDist(words)\n",
        "\n",
        "            # Score sentences based on word frequencies\n",
        "            sentence_scores = {}\n",
        "            for sentence in sentences:\n",
        "                words_in_sentence = word_tokenize(sentence.lower())\n",
        "                score = 0\n",
        "                word_count = 0\n",
        "                for word in words_in_sentence:\n",
        "                    if word in freq_dist:\n",
        "                        score += freq_dist[word]\n",
        "                        word_count += 1\n",
        "                if word_count > 0:\n",
        "                    sentence_scores[sentence] = score / word_count\n",
        "\n",
        "            # Get top sentences\n",
        "            top_sentences = heapq.nlargest(num_sentences, sentence_scores, key=sentence_scores.get)\n",
        "\n",
        "            # Return in original order\n",
        "            summary_sentences = []\n",
        "            for sentence in sentences:\n",
        "                if sentence in top_sentences:\n",
        "                    summary_sentences.append(sentence)\n",
        "\n",
        "            return \" \".join(summary_sentences)\n",
        "        except Exception as e:\n",
        "            return f\"Error with extractive summarization: {e}\"\n",
        "\n",
        "    def _chunk_text(self, text: str, max_words: int) -> List[str]:\n",
        "        \"\"\"Split text into chunks of specified word count\"\"\"\n",
        "        words = text.split()\n",
        "        chunks = []\n",
        "        for i in range(0, len(words), max_words):\n",
        "            chunk = \" \".join(words[i:i + max_words])\n",
        "            chunks.append(chunk)\n",
        "        return chunks\n",
        "\n",
        "    def compare_models(self, text: str) -> Dict[str, str]:\n",
        "        \"\"\"Compare different summarization approaches\"\"\"\n",
        "        print(\"üîÑ Generating summaries with different models...\")\n",
        "\n",
        "        results = {}\n",
        "\n",
        "        # Gemini summaries\n",
        "        print(\"üìù Generating Gemini summaries...\")\n",
        "        results[\"Gemini (Concise)\"] = self.gemini_summarize(text, \"concise\")\n",
        "        results[\"Gemini (Detailed)\"] = self.gemini_summarize(text, \"detailed\")\n",
        "        results[\"Gemini (Bullet Points)\"] = self.gemini_summarize(text, \"bullet_points\")\n",
        "\n",
        "        # HuggingFace summary\n",
        "        print(\"ü§ó Generating HuggingFace BART summary...\")\n",
        "        results[\"HuggingFace BART\"] = self.huggingface_summarize(text)\n",
        "\n",
        "        # Extractive summary\n",
        "        print(\"üìä Generating Extractive summary...\")\n",
        "        results[\"Extractive (Frequency-based)\"] = self.extractive_summarize(text)\n",
        "\n",
        "        return results\n",
        "\n",
        "    def analyze_summaries(self, original_text: str, summaries: Dict[str, str]) -> Dict[str, Dict]:\n",
        "        \"\"\"Analyze and compare summary characteristics\"\"\"\n",
        "        analysis = {}\n",
        "        original_word_count = len(original_text.split())\n",
        "        original_sentence_count = len(sent_tokenize(original_text))\n",
        "\n",
        "        for model_name, summary in summaries.items():\n",
        "            word_count = len(summary.split())\n",
        "            sentence_count = len(sent_tokenize(summary))\n",
        "            compression_ratio = round((1 - word_count / original_word_count) * 100, 1)\n",
        "\n",
        "            analysis[model_name] = {\n",
        "                \"word_count\": word_count,\n",
        "                \"sentence_count\": sentence_count,\n",
        "                \"compression_ratio\": f\"{compression_ratio}%\",\n",
        "                \"summary\": summary\n",
        "            }\n",
        "\n",
        "        return analysis\n",
        "\n",
        "def main():\n",
        "    # Initialize summarizer\n",
        "    summarizer = TextSummarizer()\n",
        "\n",
        "    # Sample text for testing\n",
        "    sample_text = \"\"\"\n",
        "    Artificial Intelligence (AI) has become one of the most transformative technologies of the 21st century,\n",
        "    revolutionizing industries from healthcare to finance, transportation to entertainment. At its core, AI\n",
        "    refers to the simulation of human intelligence in machines that are programmed to think and learn like humans.\n",
        "    These systems can perform tasks that typically require human intelligence, such as visual perception,\n",
        "    speech recognition, decision-making, and language translation.\n",
        "\n",
        "    The development of AI can be traced back to the 1950s when computer scientists first began exploring\n",
        "    the possibility of creating machines that could mimic human thought processes. Early pioneers like\n",
        "    Alan Turing proposed the famous Turing Test as a measure of machine intelligence. However, it wasn't\n",
        "    until recent decades, with the advent of powerful computers and vast amounts of data, that AI has\n",
        "    reached its current level of sophistication.\n",
        "\n",
        "    Machine Learning, a subset of AI, has been particularly instrumental in recent breakthroughs.\n",
        "    This approach allows systems to automatically learn and improve from experience without being\n",
        "    explicitly programmed for every scenario. Deep Learning, which uses neural networks with multiple\n",
        "    layers, has enabled remarkable achievements in image recognition, natural language processing,\n",
        "    and game playing, with systems like AlphaGo defeating world champions in complex strategy games.\n",
        "\n",
        "    The applications of AI are vast and growing. In healthcare, AI systems can analyze medical images\n",
        "    to detect diseases earlier and more accurately than human doctors in some cases. In autonomous\n",
        "    vehicles, AI processes sensor data to navigate safely through traffic. In finance, AI algorithms\n",
        "    detect fraudulent transactions and make investment decisions. Virtual assistants like Siri and\n",
        "    Alexa use AI to understand and respond to natural language queries.\n",
        "\n",
        "    However, the rapid advancement of AI also raises important ethical and societal questions.\n",
        "    Concerns about job displacement, privacy, algorithmic bias, and the potential for misuse of\n",
        "    AI technologies have sparked debates among policymakers, researchers, and the public. As AI\n",
        "    systems become more powerful and ubiquitous, ensuring they are developed and deployed\n",
        "    responsibly becomes increasingly critical for society's benefit.\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"üöÄ Multi-Model Text Summarizer\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # Option to use custom text\n",
        "    use_custom = input(\"Would you like to use custom text? (y/n): \").lower().strip()\n",
        "    if use_custom == 'y':\n",
        "        print(\"\\nEnter your text (press Enter twice when finished):\")\n",
        "        lines = []\n",
        "        while True:\n",
        "            line = input()\n",
        "            if line == \"\":\n",
        "                break\n",
        "            lines.append(line)\n",
        "        text_to_summarize = \"\\n\".join(lines)\n",
        "    else:\n",
        "        text_to_summarize = sample_text\n",
        "        print(\"\\nUsing sample text about Artificial Intelligence...\")\n",
        "\n",
        "    print(f\"\\nüìÑ Original text length: {len(text_to_summarize.split())} words\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    # Generate summaries\n",
        "    start_time = time.time()\n",
        "    summaries = summarizer.compare_models(text_to_summarize)\n",
        "    end_time = time.time()\n",
        "\n",
        "    # Analyze results\n",
        "    analysis = summarizer.analyze_summaries(text_to_summarize, summaries)\n",
        "\n",
        "    # Display results\n",
        "    print(f\"\\n‚è±Ô∏è  Total processing time: {end_time - start_time:.2f} seconds\")\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"üìä SUMMARY COMPARISON RESULTS\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    for model_name, data in analysis.items():\n",
        "        print(f\"\\nüîπ {model_name}\")\n",
        "        print(f\"   Words: {data['word_count']} | Sentences: {data['sentence_count']} | Compression: {data['compression_ratio']}\")\n",
        "        print(f\"   Summary: {data['summary']}\")\n",
        "        print(\"-\" * 80)\n",
        "\n",
        "    # Performance comparison table\n",
        "    print(\"\\nüìà PERFORMANCE METRICS\")\n",
        "    print(\"-\" * 60)\n",
        "    print(f\"{'Model':<25} {'Words':<8} {'Sentences':<10} {'Compression':<12}\")\n",
        "    print(\"-\" * 60)\n",
        "    for model_name, data in analysis.items():\n",
        "        print(f\"{model_name:<25} {data['word_count']:<8} {data['sentence_count']:<10} {data['compression_ratio']:<12}\")\n",
        "\n",
        "    print(\"\\n‚úÖ Analysis complete!\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Install required packages (run these in terminal if needed):\n",
        "    # pip install google-generativeai transformers torch nltk\n",
        "\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "drhAo4SlnOQP",
        "outputId": "da0f7db3-b70c-4221-8f5a-84df4f462aef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ NLTK data downloaded successfully\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ HuggingFace BART model loaded successfully\n",
            "üöÄ Multi-Model Text Summarizer\n",
            "==================================================\n",
            "Would you like to use custom text? (y/n): n\n",
            "\n",
            "Using sample text about Artificial Intelligence...\n",
            "\n",
            "üìÑ Original text length: 326 words\n",
            "--------------------------------------------------\n",
            "üîÑ Generating summaries with different models...\n",
            "üìù Generating Gemini summaries...\n",
            "ü§ó Generating HuggingFace BART summary...\n",
            "üìä Generating Extractive summary...\n",
            "\n",
            "‚è±Ô∏è  Total processing time: 52.74 seconds\n",
            "\n",
            "================================================================================\n",
            "üìä SUMMARY COMPARISON RESULTS\n",
            "================================================================================\n",
            "\n",
            "üîπ Gemini (Concise)\n",
            "   Words: 61 | Sentences: 3 | Compression: 81.3%\n",
            "   Summary: AI, simulating human intelligence in machines, is rapidly transforming numerous industries through advancements in machine and deep learning.  Its applications range from healthcare diagnostics to autonomous vehicles and financial analysis, but ethical concerns regarding job displacement, bias, and misuse necessitate responsible development and deployment.  The field's evolution from its 1950s origins has been propelled by increased computing power and data availability.\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "üîπ Gemini (Detailed)\n",
            "   Words: 189 | Sentences: 8 | Compression: 42.0%\n",
            "   Summary: This text provides an overview of Artificial Intelligence (AI), its history, current capabilities, applications, and associated ethical concerns.  AI, defined as the simulation of human intelligence in machines, is revolutionizing numerous sectors, including healthcare, finance, transportation, and entertainment. Its development, traceable to the 1950s and the work of pioneers like Alan Turing, has significantly accelerated in recent decades due to advancements in computing power and data availability.\n",
            "\n",
            "Machine Learning, a crucial subfield, allows AI systems to learn from data without explicit programming, while Deep Learning, using multi-layered neural networks, powers breakthroughs in areas such as image recognition and natural language processing, exemplified by AlphaGo's success in strategic games.  The text highlights diverse AI applications:  early disease detection in healthcare, autonomous vehicle navigation, fraud detection in finance, and the functionality of virtual assistants.\n",
            "\n",
            "Despite its transformative potential, the text emphasizes the crucial ethical considerations accompanying AI's rapid progress.  Concerns about job displacement, privacy violations, algorithmic bias, and the potential for malicious use necessitate careful consideration by policymakers, researchers, and the public.  The responsible development and deployment of increasingly powerful and prevalent AI systems are presented as paramount for societal well-being.\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "üîπ Gemini (Bullet Points)\n",
            "   Words: 112 | Sentences: 6 | Compression: 65.6%\n",
            "   Summary: * **AI's Core Function:** Simulates human intelligence in machines, enabling tasks like visual perception, speech recognition, decision-making, and language translation.\n",
            "\n",
            "* **Historical Development:**  Origins in the 1950s, but recent advancements fueled by powerful computers and large datasets.\n",
            "\n",
            "* **Key Subset: Machine Learning:** Allows systems to learn and improve from experience without explicit programming.\n",
            "\n",
            "* **Sub-Subset: Deep Learning:** Utilizes neural networks for breakthroughs in image recognition, natural language processing, and game playing (e.g., AlphaGo).\n",
            "\n",
            "* **Broad Applications:**  Healthcare (disease detection), autonomous vehicles (navigation), finance (fraud detection, investment), and virtual assistants (natural language processing).\n",
            "\n",
            "* **Ethical and Societal Concerns:** Job displacement, privacy violations, algorithmic bias, and potential misuse require careful consideration and responsible development.\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "üîπ HuggingFace BART\n",
            "   Words: 62 | Sentences: 4 | Compression: 81.0%\n",
            "   Summary: Artificial Intelligence (AI) has become one of the most transformative technologies of the 21st century. At its core, AI refers to the simulation of human intelligence in machines that are programmed to think and learn like humans. Machine Learning, a subset of AI, has been particularly instrumental in recent breakthroughs. The rapid advancement of AI also raises important ethical and societal questions.\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "üîπ Extractive (Frequency-based)\n",
            "   Words: 43 | Sentences: 3 | Compression: 86.8%\n",
            "   Summary: At its core, AI \n",
            "    refers to the simulation of human intelligence in machines that are programmed to think and learn like humans. Machine Learning, a subset of AI, has been particularly instrumental in recent breakthroughs. The applications of AI are vast and growing.\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "üìà PERFORMANCE METRICS\n",
            "------------------------------------------------------------\n",
            "Model                     Words    Sentences  Compression \n",
            "------------------------------------------------------------\n",
            "Gemini (Concise)          61       3          81.3%       \n",
            "Gemini (Detailed)         189      8          42.0%       \n",
            "Gemini (Bullet Points)    112      6          65.6%       \n",
            "HuggingFace BART          62       4          81.0%       \n",
            "Extractive (Frequency-based) 43       3          86.8%       \n",
            "\n",
            "‚úÖ Analysis complete!\n"
          ]
        }
      ]
    }
  ]
}